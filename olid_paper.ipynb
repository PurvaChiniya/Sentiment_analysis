{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert_olid_paper.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PurvaChiniya/Sentiment_analysis/blob/master/olid_paper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhbCFZJkBqAE",
        "colab_type": "text"
      },
      "source": [
        "# IMPORT LIBRARIES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9ynECRb1MCp",
        "colab_type": "code",
        "outputId": "2cf8ff43-5c9b-4d7e-8758-e749c8061d9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79IB050SBuLV",
        "colab_type": "text"
      },
      "source": [
        "# DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1A8CTbm6viN",
        "colab_type": "code",
        "outputId": "e402268c-6cf1-45bd-8525-b93f5c4e4f04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/drive/My Drive/ml-lab"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/ml-lab\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwtjGsxl6zD1",
        "colab_type": "code",
        "outputId": "271db32c-8f39-4674-b68e-93426a883f00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "data = pd.read_csv('./olid-training-v1.0.tsv',sep='\\t', header=None)\n",
        "msk = np.random.rand(len(data)) < 0.8\n",
        "train_data = data[msk]\n",
        "test_data = data[~msk]\n",
        "data.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id</td>\n",
              "      <td>tweet</td>\n",
              "      <td>subtask_a</td>\n",
              "      <td>subtask_b</td>\n",
              "      <td>subtask_c</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>86426</td>\n",
              "      <td>@USER She should ask a few native Americans wh...</td>\n",
              "      <td>OFF</td>\n",
              "      <td>UNT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>90194</td>\n",
              "      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n",
              "      <td>OFF</td>\n",
              "      <td>TIN</td>\n",
              "      <td>IND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16820</td>\n",
              "      <td>Amazon is investigating Chinese employees who ...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>62688</td>\n",
              "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
              "      <td>OFF</td>\n",
              "      <td>UNT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       0  ...          4\n",
              "0     id  ...  subtask_c\n",
              "1  86426  ...        NaN\n",
              "2  90194  ...        IND\n",
              "3  16820  ...        NaN\n",
              "4  62688  ...        NaN\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E72v57IU3cy_",
        "colab_type": "text"
      },
      "source": [
        "# DATA PREPROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ki1sL6of3fST",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "f57c4e91-78eb-4f76-8c69-1cc52a1547e4"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import io\n",
        "import string\n",
        "import nltk\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from gensim.models import FastText\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "pd.options.mode.chained_assignment = None  # default='warn'\n",
        "\n",
        "REDUNDANT_INFO = ['@USER', 'URL']\n",
        "\n",
        "EMOJI_PATTERN = re.compile(\n",
        "    u\"(\\ud83d[\\ude00-\\ude4f])|\"\n",
        "    u\"(\\ud83c[\\udf00-\\uffff])|\"\n",
        "    u\"(\\ud83d[\\u0000-\\uddff])|\"\n",
        "    u\"(\\ud83d[\\ude80-\\udeff])|\"\n",
        "    u\"(\\ud83c[\\udde0-\\uddff])\"\n",
        "    \"+\", flags=re.UNICODE)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lb7__qdZ3fWU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lemmatize(x):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    return lemmatizer.lemmatize(x, pos='v')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J74L_oPX3fZp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Preprocessing:\n",
        "\n",
        "    @staticmethod\n",
        "    def remove_unnecessary_information(x):\n",
        "        \"\"\"\n",
        "        Remove unnecessary information from a string.\n",
        "        :param x: A string.\n",
        "        :return: A cleaned string.\n",
        "        \"\"\"\n",
        "        for i in REDUNDANT_INFO:\n",
        "            x = x.replace(i, '')\n",
        "\n",
        "        # Remove emojis.\n",
        "        x = EMOJI_PATTERN.sub(r'', x)\n",
        "\n",
        "        # Word tokenizer.\n",
        "        tokenizer = RegexpTokenizer(r'\\w+')\n",
        "        x = tokenizer.tokenize(x)\n",
        "\n",
        "        # Remove stop words.\n",
        "        stop_words = set(stopwords.words('english'))\n",
        "        x = [w for w in x if w not in stop_words]\n",
        "        x = [w for w in x if not w.isdigit()]\n",
        "        x = [w for w in x if w not in string.punctuation]\n",
        "        x = [lemmatize(w) for w in x]\n",
        "\n",
        "        return x\n",
        "\n",
        "    @staticmethod\n",
        "    def load_embeddings(file_name):\n",
        "        \"\"\"\n",
        "        Load the embeddings.\n",
        "        :param file_name: Path to embeddings.\n",
        "        :return: Embeddings.\n",
        "        \"\"\"\n",
        "        fin = io.open(file_name, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
        "        n, d = map(int, fin.readline().split())\n",
        "        print(\"Number of words in FastText embeddings: \", n, \" Dimension:\", d)\n",
        "        data = {}\n",
        "        for line in fin:\n",
        "            tokens = line.rstrip().split(' ')\n",
        "            word = tokens[0]\n",
        "            representation = np.asarray(tokens[1:], dtype='float32')\n",
        "            data[word] = representation\n",
        "        fin.close()\n",
        "        return data\n",
        "\n",
        "    @staticmethod\n",
        "    def load_data(file_name):\n",
        "        \"\"\"\n",
        "        Load data from disk.\n",
        "        :param file_name: Path to the file.\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        return pd.read_csv(file_name, sep=\"\\t\")\n",
        "\n",
        "    @staticmethod\n",
        "    def filter_data(data, subtask='subtask_a'):\n",
        "        \"\"\"\n",
        "        Filter data by removing redundant information from tweets.\n",
        "        :param data: Data as a pandas data frame.\n",
        "        :return: Filtered data.\n",
        "        \"\"\"\n",
        "\n",
        "        data.dropna(subset=[subtask], inplace=True)\n",
        "\n",
        "        print(\"Labels: \", data[subtask].unique())\n",
        "\n",
        "        if subtask == 'subtask_a':\n",
        "            y = data[[\"subtask_a\"]]\n",
        "            y['subtask_a'].replace(to_replace=['OFF', 'NOT'], value=[0, 1], inplace=True)\n",
        "        elif subtask == 'subtask_b':\n",
        "            zero_category = data[subtask] == 'UNT'\n",
        "            zero_category_data = data[zero_category]\n",
        "            data = data.append([zero_category_data] * 7, ignore_index=True)\n",
        "            y = data[[\"subtask_b\"]]\n",
        "            y['subtask_b'].replace(to_replace=['UNT', 'TIN'], value=[0, 1], inplace=True)\n",
        "        elif subtask == 'subtask_c':\n",
        "            one_category = data[subtask] == 'GRP'\n",
        "            one_category_data = data[one_category]\n",
        "            data = data.append([one_category_data] * 1, ignore_index=True)\n",
        "\n",
        "            two_category = data[subtask] == 'OTH'\n",
        "            two_category_data = data[two_category]\n",
        "            data = data.append([two_category_data] * 5, ignore_index=True)\n",
        "\n",
        "            y = data[[\"subtask_c\"]]\n",
        "            y['subtask_c'].replace(to_replace=['IND', 'GRP', 'OTH'], value=[0, 1, 2], inplace=True)\n",
        "\n",
        "        X = data[[\"tweet\"]]\n",
        "        X['tweet'] = X['tweet'].map(lambda x: Preprocessing.remove_unnecessary_information(x))\n",
        "\n",
        "        print(y[subtask].value_counts())\n",
        "\n",
        "        return pd.Series(X['tweet']), y.values\n",
        "\n",
        "    @staticmethod\n",
        "    def filter_test_data(data):\n",
        "        \"\"\"\n",
        "        Filter data by removing redundant information from tweets.\n",
        "        :param data: Data as a pandas data frame.\n",
        "        :return: Filtered data.\n",
        "        \"\"\"\n",
        "\n",
        "        X = data[[\"tweet\"]]\n",
        "\n",
        "        X['tweet'] = X['tweet'].map(lambda x: Preprocessing.remove_unnecessary_information(x))\n",
        "\n",
        "        return pd.Series(data['id']), pd.Series(X['tweet'])\n",
        "\n",
        "    @staticmethod\n",
        "    def prepare_data(X_train, X_test, max_tweet_length):\n",
        "        \"\"\"\n",
        "        Prepare data by tokenizing it.\n",
        "        :param X_train: Train data as an ndarray.\n",
        "        :param X_test: TestA data as an ndarray.\n",
        "        :param max_tweet_length: A maximum length of a tweet.\n",
        "        :return: Padded train/test data, mapping of words to the number of texts they appeared, mapping of words to indices\n",
        "        \"\"\"\n",
        "\n",
        "        tokenizer = tf.keras.preprocessing.text.Tokenizer(oov_token='<UNK>')\n",
        "        tokenizer.fit_on_texts(X_train.ravel())\n",
        "        train_words_to_indices = tokenizer.texts_to_sequences(X_train.ravel())\n",
        "        test_words_to_indices = tokenizer.texts_to_sequences(X_test.ravel())\n",
        "\n",
        "        # Add zeroes to to the tweet, if its length less than max_tweet_length.\n",
        "        train_padded = tf.keras.preprocessing.sequence.pad_sequences(train_words_to_indices, maxlen=max_tweet_length,\n",
        "                                                                     padding='post', truncating='post')\n",
        "        test_padded = tf.keras.preprocessing.sequence.pad_sequences(test_words_to_indices, maxlen=max_tweet_length,\n",
        "                                                                    padding='post', truncating='post')\n",
        "\n",
        "        print(\"Shape of the train data: \", train_padded.shape)\n",
        "        print(\"Shape of the test data: \", test_padded.shape)\n",
        "\n",
        "        # len(tokenizer.word_docs) + 2, because of UNKNOWN and PAD.\n",
        "        return train_padded, test_padded, tokenizer.word_docs, tokenizer.word_index, len(tokenizer.word_docs) + 3\n",
        "\n",
        "    @staticmethod\n",
        "    def create_embedding_matrix(word2idx, dimension, embeddings_file_name):\n",
        "        \"\"\"\n",
        "        Create an embedding matrix.\n",
        "        :param word2idx: A mapping from a word to an index.\n",
        "        :param dimension: A dimension of embeddings.\n",
        "        :param embeddings_file_name: Path to the file of GloVe embeddings.\n",
        "        :return: An embedding matrix.\n",
        "        \"\"\"\n",
        "        max_words = len(word2idx) + 1\n",
        "        embedding_matrix = np.zeros((max_words, dimension))\n",
        "\n",
        "        # Load GloVe embeddings.\n",
        "        embeddings_data = Preprocessing.load_embeddings(embeddings_file_name)\n",
        "\n",
        "        zeros = 1\n",
        "        for word, index in word2idx.items():\n",
        "            embedding_vector = embeddings_data.get(word)\n",
        "            if embedding_vector is not None:\n",
        "                embedding_matrix[index] = embedding_vector\n",
        "            else:\n",
        "                zeros += 1\n",
        "\n",
        "        print(\"Shape of the embedding matrix: \", embedding_matrix.shape)\n",
        "        print(\"{} words are not found\".format(zeros))\n",
        "\n",
        "        return embedding_matrix\n",
        "\n",
        "    @staticmethod\n",
        "    def get_tweet_embedding(data):\n",
        "\n",
        "        model = FastText(size=300, window=5, min_count=1, seed=42, workers=2, alpha=0.025, min_alpha=0.00025)\n",
        "\n",
        "        docs = []\n",
        "\n",
        "        for index, tweet in data.iteritems():\n",
        "            words = word_tokenize(tweet.lower())\n",
        "            docs.append(words)\n",
        "\n",
        "        model.train(docs, total_examples=model.corpus_count, epochs=10)\n",
        "        return np.asarray([model.wv[tweet] for i, tweet in data.iteritems()])\n",
        "\n",
        "    @staticmethod\n",
        "    def map_indices_to_embeddings(x_data, y_data, embedding_matrix):\n",
        "\n",
        "        mapped_data = np.zeros((x_data.shape[0] * x_data.shape[1], embedding_matrix.shape[1]))\n",
        "        mapped_labels = np.zeros((mapped_data.shape[0], 1))\n",
        "\n",
        "        index = 0\n",
        "        for r in range(0, x_data.shape[0]):\n",
        "\n",
        "            # Iterate over rows\n",
        "            row = x_data[r, :]\n",
        "\n",
        "            for c in range(0, row.size):\n",
        "                # Iterate over columns\n",
        "                embedding = embedding_matrix[x_data[r, c]]\n",
        "                for e in range(0, embedding_matrix.shape[1]):\n",
        "                    mapped_data[index, e] = embedding[e]\n",
        "                mapped_labels[index, 0] = y_data[r, 0]\n",
        "                index += 1\n",
        "\n",
        "        return mapped_data, mapped_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhEPkTuM3fdq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def shuffle_batch(X, y, batch_size):\n",
        "    \"\"\"\n",
        "    Create batches.\n",
        "    :param X: Features\n",
        "    :param y: Labels\n",
        "    :param batch_size:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    rnd_idx = np.random.permutation(len(X))\n",
        "    n_batches = len(X) // batch_size\n",
        "    for batch_idx in np.array_split(rnd_idx, n_batches):\n",
        "        X_batch, y_batch = X[batch_idx], y[batch_idx]\n",
        "        yield X_batch, np.reshape(y_batch, (y_batch.shape[0],))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxdkF5gG39Va",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from datetime import datetime\n",
        "#from Utils import shuffle_batch\n",
        "#from Preprocessing import Preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score as sklearn_f1_score\n",
        "from tensorflow.python.ops.rnn import bidirectional_dynamic_rnn as bi_rnn\n",
        "\n",
        "# Hyperparameters:\n",
        "EMBEDDINGS_FILENAME = \"./crawl-300d-2M.vec\"\n",
        "EMBEDDING_DIMENSION = 300\n",
        "BATCH_SIZE = 128\n",
        "MAX_TWEET_LENGTH = 20\n",
        "EPOCHS = 100\n",
        "LSTM_NEURONS = 256\n",
        "NEURONS_HIDDEN_LAYER_1 = 128\n",
        "RNN_LAYERS = 3\n",
        "DROPOUT_KEEP_PROBABILITY = 0.5\n",
        "NEURONS_SOFTMAX = 2\n",
        "LOG_DIR = \"./model_output\"\n",
        "LEARNING_RATE = 0.001\n",
        "TRAINABLE_EMBEDDINGS = False\n",
        "LAMBDA_L2_REG = 0.00001\n",
        "SUBTASK = 'subtask_a'\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuuziReoEG_b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9773c6b1-99f4-4105-d2bd-87dd1d48c42e"
      },
      "source": [
        "pwd"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/ml-lab'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TpoHfDC4Ty1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "c8b6dadb-0372-4e45-f4ce-198c388ef4ca"
      },
      "source": [
        "# Load and filter data.\n",
        "X, y = Preprocessing.filter_data(Preprocessing.load_data(\"/content/drive/My Drive/ml-lab/olid-training-v1.0.tsv\"), SUBTASK)\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Tokenize data.\n",
        "train_data, test_data, vocab_freq, word2idx, vocab_size = Preprocessing.prepare_data(x_train, x_test,\n",
        "                                                                                     MAX_TWEET_LENGTH)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Labels:  ['OFF' 'NOT']\n",
            "1    8840\n",
            "0    4400\n",
            "Name: subtask_a, dtype: int64\n",
            "Shape of the train data:  (10592, 20)\n",
            "Shape of the test data:  (2648, 20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0OS95Qj42XQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "6c580770-9404-4856-e8a6-fb6089d00a12"
      },
      "source": [
        "# Create an embedding matrix.\n",
        "embedding_matrix = Preprocessing.create_embedding_matrix(word2idx, EMBEDDING_DIMENSION, EMBEDDINGS_FILENAME)\n",
        "\n",
        "# Placeholders.\n",
        "X = tf.placeholder(tf.int32, [None, MAX_TWEET_LENGTH], name=\"X_input\")\n",
        "y = tf.placeholder(tf.int64, [None], name=\"y_label\")\n",
        "keep_prob = tf.placeholder_with_default(1.0, shape=())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of words in FastText embeddings:  1999995  Dimension: 300\n",
            "Shape of the embedding matrix:  (14862, 300)\n",
            "2055 words are not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CrM4r-54JRx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "52f411cf-69d3-41ae-b76f-a380d3b67bb6"
      },
      "source": [
        "\n",
        "\n",
        "# Split data.\n",
        "\n",
        "\n",
        "\n",
        "# Define the variable that will hold the embedding.\n",
        "embeddings = tf.get_variable(name=\"embeddings\", shape=[vocab_size, EMBEDDING_DIMENSION],\n",
        "                             initializer=tf.constant_initializer(embedding_matrix), trainable=TRAINABLE_EMBEDDINGS)\n",
        "\n",
        "# Find the embeddings.\n",
        "x_embedded = tf.nn.embedding_lookup(embeddings, X)\n",
        "print(\"Input shape: \", x_embedded.shape)\n",
        "\n",
        "# A dynamic RNN.\n",
        "lstm_cells = [tf.nn.rnn_cell.LSTMCell(num_units=LSTM_NEURONS, name='lstm_cell')\n",
        "              for layer in range(RNN_LAYERS)]\n",
        "cells_drop = [tf.nn.rnn_cell.DropoutWrapper(cell, input_keep_prob=keep_prob)\n",
        "              for cell in lstm_cells]\n",
        "multi_cell = tf.nn.rnn_cell.MultiRNNCell(cells_drop)\n",
        "\n",
        "# A bidirectional RNN is used.\n",
        "outputs, states = bi_rnn(multi_cell, multi_cell, inputs=x_embedded, dtype=tf.float32)\n",
        "print(\"RNN forward output shape: \", outputs[0].shape)\n",
        "print(\"RNN backward output shape: \", outputs[1].shape)\n",
        "\n",
        "outputs = tf.add(outputs[0][:, -1, :], outputs[1][:, -1, :])\n",
        "print(\"RNN squeezed output shape: \", outputs.shape)\n",
        "\n",
        "# A hidden layer.\n",
        "hidden1 = tf.layers.dense(outputs,\n",
        "                          NEURONS_HIDDEN_LAYER_1, name=\"hidden_1\", activation='relu')\n",
        "print(\"Hidden layer shape: \", hidden1.shape)\n",
        "\n",
        "# A classification layer.\n",
        "logits = tf.layers.dense(hidden1, NEURONS_SOFTMAX, name=\"softmax\", activation='softmax')\n",
        "print(\"Logits shape: \", logits.shape)\n",
        "\n",
        "# Loss and optimizer.\n",
        "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
        "loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
        "\n",
        "l2 = LAMBDA_L2_REG * sum([\n",
        "    tf.nn.l2_loss(tf_var)\n",
        "    for tf_var in tf.trainable_variables()\n",
        "    if (\"bias\" not in tf_var.name or \"carry_b\" not in tf_var.name)]\n",
        ")\n",
        "\n",
        "loss += l2\n",
        "print(\"L2 regularized loss: \", loss)\n",
        "\n",
        "optimizer = tf.train.RMSPropOptimizer(learning_rate=LEARNING_RATE)\n",
        "training_op = optimizer.minimize(loss)\n",
        "\n",
        "# Predictions and accuracy.\n",
        "predictions = tf.argmax(logits, 1, name=\"predictions\")\n",
        "correct_predictions = tf.equal(predictions, y)\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32), name='accuracy')\n",
        "\n",
        "# Initializer.\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "# Saver.\n",
        "saver = tf.train.Saver()\n",
        "\n",
        "# Summary information for saving.\n",
        "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
        "acc_summary = tf.summary.scalar('Accuracy', accuracy)\n",
        "summary_op = tf.summary.merge_all()\n",
        "logdir = \"{}/run-{}/\".format(LOG_DIR, now)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    summary_writer_train = tf.summary.FileWriter(logdir + '/train', tf.get_default_graph())\n",
        "    summary_writer_test = tf.summary.FileWriter(logdir + '/test')\n",
        "\n",
        "    init.run()\n",
        "    for epoch in range(1, EPOCHS + 1):\n",
        "        X_batch = None\n",
        "        y_batch = None\n",
        "        for X_batch, y_batch in shuffle_batch(train_data, y_train, BATCH_SIZE):\n",
        "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch, keep_prob: DROPOUT_KEEP_PROBABILITY})\n",
        "\n",
        "        # Accuracies after one epoch.\n",
        "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
        "        acc_test = accuracy.eval(feed_dict={X: test_data, y: np.reshape(y_test, (y_test.shape[0],))})\n",
        "\n",
        "        # Get predictions for the test set.\n",
        "        _, y_pred = sess.run([accuracy, predictions], feed_dict={X: test_data, y: np.reshape(y_test, (y_test.shape[0],))})\n",
        "\n",
        "        # Write summaries.\n",
        "        summary_train_acc = acc_summary.eval(feed_dict={X: train_data, y: np.reshape(y_train, (y_train.shape[0],))})\n",
        "        summary_test_acc = acc_summary.eval(feed_dict={X: test_data, y: np.reshape(y_test, (y_test.shape[0],))})\n",
        "        summary_writer_train.add_summary(summary_train_acc, epoch)\n",
        "        summary_writer_test.add_summary(summary_test_acc, epoch)\n",
        "\n",
        "        print(\"Epoch: {} Last batch accuracy: {} Test accuracy: {} F1-Score: {}\".format(epoch, acc_train, acc_test,\n",
        "                                                                sklearn_f1_score(y_test, y_pred, average='macro')))\n",
        "\n",
        "    saver.save(sess, LOG_DIR + \"/tf_model\")\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0813 08:03:07.559999 140117377906560 deprecation.py:323] From <ipython-input-13-50a9569e0df3>:10: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "W0813 08:03:07.570703 140117377906560 deprecation.py:323] From <ipython-input-13-50a9569e0df3>:13: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
            "W0813 08:03:07.572912 140117377906560 deprecation.py:323] From <ipython-input-13-50a9569e0df3>:16: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
            "W0813 08:03:07.579179 140117377906560 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py:464: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Input shape:  (?, 20, 300)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0813 08:03:08.004721 140117377906560 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0813 08:03:08.014777 140117377906560 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn_cell_impl.py:961: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0813 08:03:09.079304 140117377906560 deprecation.py:323] From <ipython-input-13-50a9569e0df3>:25: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "RNN forward output shape:  (?, 20, 256)\n",
            "RNN backward output shape:  (?, 20, 256)\n",
            "RNN squeezed output shape:  (?, 256)\n",
            "Hidden layer shape:  (?, 128)\n",
            "Logits shape:  (?, 2)\n",
            "L2 regularized loss:  Tensor(\"add_11:0\", shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0813 08:03:10.858713 140117377906560 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 Last batch accuracy: 0.6201550364494324 Test accuracy: 0.6642749309539795 F1-Score: 0.3991377354209213\n",
            "Epoch: 2 Last batch accuracy: 0.6589147448539734 Test accuracy: 0.6827794313430786 F1-Score: 0.46992293063757384\n",
            "Epoch: 3 Last batch accuracy: 0.7829457521438599 Test accuracy: 0.7280966639518738 F1-Score: 0.606498910243709\n",
            "Epoch: 4 Last batch accuracy: 0.8062015771865845 Test accuracy: 0.7809667587280273 F1-Score: 0.737261320837348\n",
            "Epoch: 5 Last batch accuracy: 0.8139534592628479 Test accuracy: 0.7711480259895325 F1-Score: 0.7081857005377701\n",
            "Epoch: 6 Last batch accuracy: 0.7829457521438599 Test accuracy: 0.7749244570732117 F1-Score: 0.7438730764611754\n",
            "Epoch: 7 Last batch accuracy: 0.8062015771865845 Test accuracy: 0.7768126726150513 F1-Score: 0.7192531514702376\n",
            "Epoch: 8 Last batch accuracy: 0.8062015771865845 Test accuracy: 0.7802115082740784 F1-Score: 0.7169318933215781\n",
            "Epoch: 9 Last batch accuracy: 0.8062015771865845 Test accuracy: 0.7794561982154846 F1-Score: 0.7330556691008319\n",
            "Epoch: 10 Last batch accuracy: 0.8449612259864807 Test accuracy: 0.7790785431861877 F1-Score: 0.7318809612947144\n",
            "Epoch: 11 Last batch accuracy: 0.8062015771865845 Test accuracy: 0.7817220687866211 F1-Score: 0.7343718652268838\n",
            "Epoch: 12 Last batch accuracy: 0.8914728760719299 Test accuracy: 0.7851208448410034 F1-Score: 0.7313127231426764\n",
            "Epoch: 13 Last batch accuracy: 0.8062015771865845 Test accuracy: 0.7817220687866211 F1-Score: 0.729442843283941\n",
            "Epoch: 14 Last batch accuracy: 0.8759689927101135 Test accuracy: 0.773413896560669 F1-Score: 0.7029060900511687\n",
            "Epoch: 15 Last batch accuracy: 0.8217054009437561 Test accuracy: 0.7737915515899658 F1-Score: 0.7082605664021584\n",
            "Epoch: 16 Last batch accuracy: 0.8682170510292053 Test accuracy: 0.7726585865020752 F1-Score: 0.7248279328744877\n",
            "Epoch: 17 Last batch accuracy: 0.8449612259864807 Test accuracy: 0.7794561982154846 F1-Score: 0.7309864368756662\n",
            "Epoch: 18 Last batch accuracy: 0.8759689927101135 Test accuracy: 0.7798338532447815 F1-Score: 0.7225752714209853\n",
            "Epoch: 19 Last batch accuracy: 0.7674418687820435 Test accuracy: 0.7753021121025085 F1-Score: 0.7192723631449207\n",
            "Epoch: 20 Last batch accuracy: 0.8527131676673889 Test accuracy: 0.7753021121025085 F1-Score: 0.7107420491974982\n",
            "Epoch: 21 Last batch accuracy: 0.8062015771865845 Test accuracy: 0.7737915515899658 F1-Score: 0.7144669134689035\n",
            "Epoch: 22 Last batch accuracy: 0.8837209343910217 Test accuracy: 0.7805891036987305 F1-Score: 0.7380590337989057\n",
            "Epoch: 23 Last batch accuracy: 0.8449612259864807 Test accuracy: 0.778323233127594 F1-Score: 0.7279983508857952\n",
            "Epoch: 24 Last batch accuracy: 0.8682170510292053 Test accuracy: 0.7817220687866211 F1-Score: 0.7361997027182801\n",
            "Epoch: 25 Last batch accuracy: 0.8837209343910217 Test accuracy: 0.7768126726150513 F1-Score: 0.7291310224361987\n",
            "Epoch: 26 Last batch accuracy: 0.8992248177528381 Test accuracy: 0.773413896560669 F1-Score: 0.7346587037556616\n",
            "Epoch: 27 Last batch accuracy: 0.8914728760719299 Test accuracy: 0.7760574221611023 F1-Score: 0.7300678756561298\n",
            "Epoch: 28 Last batch accuracy: 0.8527131676673889 Test accuracy: 0.7715256810188293 F1-Score: 0.7209852354019445\n",
            "Epoch: 29 Last batch accuracy: 0.8682170510292053 Test accuracy: 0.7658610343933105 F1-Score: 0.7114355036133837\n",
            "Epoch: 30 Last batch accuracy: 0.8527131676673889 Test accuracy: 0.7722809910774231 F1-Score: 0.7199126660993858\n",
            "Epoch: 31 Last batch accuracy: 0.8992248177528381 Test accuracy: 0.7753021121025085 F1-Score: 0.7277158467490026\n",
            "Epoch: 32 Last batch accuracy: 0.8604651093482971 Test accuracy: 0.7556646466255188 F1-Score: 0.7137768377651199\n",
            "Epoch: 33 Last batch accuracy: 0.8449612259864807 Test accuracy: 0.7787008881568909 F1-Score: 0.7285698792693891\n",
            "Epoch: 34 Last batch accuracy: 0.8682170510292053 Test accuracy: 0.7771903276443481 F1-Score: 0.7385492286941184\n",
            "Epoch: 35 Last batch accuracy: 0.8837209343910217 Test accuracy: 0.7737915515899658 F1-Score: 0.725464437291511\n",
            "Epoch: 36 Last batch accuracy: 0.8914728760719299 Test accuracy: 0.7677492499351501 F1-Score: 0.709345191404148\n",
            "Epoch: 37 Last batch accuracy: 0.8992248177528381 Test accuracy: 0.7745468020439148 F1-Score: 0.735537333869779\n",
            "Epoch: 38 Last batch accuracy: 0.9147287011146545 Test accuracy: 0.773413896560669 F1-Score: 0.7209694415173868\n",
            "Epoch: 39 Last batch accuracy: 0.930232584476471 Test accuracy: 0.7703927755355835 F1-Score: 0.7294601045470646\n",
            "Epoch: 40 Last batch accuracy: 0.9224806427955627 Test accuracy: 0.7662386894226074 F1-Score: 0.7207237922129346\n",
            "Epoch: 41 Last batch accuracy: 0.8914728760719299 Test accuracy: 0.7696374654769897 F1-Score: 0.7224337736964381\n",
            "Epoch: 42 Last batch accuracy: 0.9147287011146545 Test accuracy: 0.7741692066192627 F1-Score: 0.7260280798449221\n",
            "Epoch: 43 Last batch accuracy: 0.9457364082336426 Test accuracy: 0.778323233127594 F1-Score: 0.7422186356050584\n",
            "Epoch: 44 Last batch accuracy: 0.8992248177528381 Test accuracy: 0.7726585865020752 F1-Score: 0.7272953709380748\n",
            "Epoch: 45 Last batch accuracy: 0.8837209343910217 Test accuracy: 0.7741692066192627 F1-Score: 0.7295064269178944\n",
            "Epoch: 46 Last batch accuracy: 0.8992248177528381 Test accuracy: 0.7635951638221741 F1-Score: 0.71450872328333\n",
            "Epoch: 47 Last batch accuracy: 0.8992248177528381 Test accuracy: 0.7745468020439148 F1-Score: 0.7278372452760999\n",
            "Epoch: 48 Last batch accuracy: 0.9147287011146545 Test accuracy: 0.7635951638221741 F1-Score: 0.7153667946242697\n",
            "Epoch: 49 Last batch accuracy: 0.9147287011146545 Test accuracy: 0.7722809910774231 F1-Score: 0.7157373419191927\n",
            "Epoch: 50 Last batch accuracy: 0.930232584476471 Test accuracy: 0.7590634226799011 F1-Score: 0.7197297871210915\n",
            "Epoch: 51 Last batch accuracy: 0.9069767594337463 Test accuracy: 0.7719033360481262 F1-Score: 0.7160991105554004\n",
            "Epoch: 52 Last batch accuracy: 0.9534883499145508 Test accuracy: 0.768126904964447 F1-Score: 0.7300950153622223\n",
            "Epoch: 53 Last batch accuracy: 0.9147287011146545 Test accuracy: 0.7567976117134094 F1-Score: 0.7284175228310502\n",
            "Epoch: 54 Last batch accuracy: 0.8682170510292053 Test accuracy: 0.7737915515899658 F1-Score: 0.7199581990270804\n",
            "Epoch: 55 Last batch accuracy: 0.8992248177528381 Test accuracy: 0.7654833793640137 F1-Score: 0.7214329093467071\n",
            "Epoch: 56 Last batch accuracy: 0.9147287011146545 Test accuracy: 0.7620846033096313 F1-Score: 0.7190856847261176\n",
            "Epoch: 57 Last batch accuracy: 0.9147287011146545 Test accuracy: 0.7805891036987305 F1-Score: 0.740298157258837\n",
            "Epoch: 58 Last batch accuracy: 0.9457364082336426 Test accuracy: 0.7737915515899658 F1-Score: 0.7378063103279041\n",
            "Epoch: 59 Last batch accuracy: 0.9069767594337463 Test accuracy: 0.768126904964447 F1-Score: 0.7264107446588682\n",
            "Epoch: 60 Last batch accuracy: 0.8914728760719299 Test accuracy: 0.7696374654769897 F1-Score: 0.723671389156521\n",
            "Epoch: 61 Last batch accuracy: 0.9534883499145508 Test accuracy: 0.768126904964447 F1-Score: 0.7304501273582498\n",
            "Epoch: 62 Last batch accuracy: 0.9457364082336426 Test accuracy: 0.759441077709198 F1-Score: 0.7288831475847868\n",
            "Epoch: 63 Last batch accuracy: 0.8992248177528381 Test accuracy: 0.7700151205062866 F1-Score: 0.7346254575793405\n",
            "Epoch: 64 Last batch accuracy: 0.9379844665527344 Test accuracy: 0.7647280693054199 F1-Score: 0.7142446868122779\n",
            "Epoch: 65 Last batch accuracy: 0.9379844665527344 Test accuracy: 0.7654833793640137 F1-Score: 0.7265655930932042\n",
            "Epoch: 66 Last batch accuracy: 0.8992248177528381 Test accuracy: 0.7673715949058533 F1-Score: 0.7264668319435054\n",
            "Epoch: 67 Last batch accuracy: 0.9069767594337463 Test accuracy: 0.7726585865020752 F1-Score: 0.7319441455015067\n",
            "Epoch: 68 Last batch accuracy: 0.9457364082336426 Test accuracy: 0.7741692066192627 F1-Score: 0.739995901682412\n",
            "Epoch: 69 Last batch accuracy: 0.8759689927101135 Test accuracy: 0.7692598104476929 F1-Score: 0.7220829998782127\n",
            "Epoch: 70 Last batch accuracy: 0.930232584476471 Test accuracy: 0.7628398537635803 F1-Score: 0.7278058547118507\n",
            "Epoch: 71 Last batch accuracy: 0.9224806427955627 Test accuracy: 0.7707703709602356 F1-Score: 0.729811497605541\n",
            "Epoch: 72 Last batch accuracy: 0.8992248177528381 Test accuracy: 0.7673715949058533 F1-Score: 0.7381941073900304\n",
            "Epoch: 73 Last batch accuracy: 0.9379844665527344 Test accuracy: 0.7692598104476929 F1-Score: 0.7327268705532686\n",
            "Epoch: 74 Last batch accuracy: 0.8992248177528381 Test accuracy: 0.7673715949058533 F1-Score: 0.7281326855857495\n",
            "Epoch: 75 Last batch accuracy: 0.9379844665527344 Test accuracy: 0.7647280693054199 F1-Score: 0.7226895601453904\n",
            "Epoch: 76 Last batch accuracy: 0.961240291595459 Test accuracy: 0.7647280693054199 F1-Score: 0.723072765194912\n",
            "Epoch: 77 Last batch accuracy: 0.9689922332763672 Test accuracy: 0.7771903276443481 F1-Score: 0.7339047022114429\n",
            "Epoch: 78 Last batch accuracy: 0.8837209343910217 Test accuracy: 0.7635951638221741 F1-Score: 0.7210637233818429\n",
            "Epoch: 79 Last batch accuracy: 0.930232584476471 Test accuracy: 0.7715256810188293 F1-Score: 0.7291882018934378\n",
            "Epoch: 80 Last batch accuracy: 0.9457364082336426 Test accuracy: 0.7669939398765564 F1-Score: 0.7154510582528921\n",
            "Epoch: 81 Last batch accuracy: 0.9457364082336426 Test accuracy: 0.768882155418396 F1-Score: 0.72953454418736\n",
            "Epoch: 82 Last batch accuracy: 0.9379844665527344 Test accuracy: 0.7749244570732117 F1-Score: 0.7313939057259\n",
            "Epoch: 83 Last batch accuracy: 0.9224806427955627 Test accuracy: 0.7666162848472595 F1-Score: 0.7236621339392579\n",
            "Epoch: 84 Last batch accuracy: 0.9379844665527344 Test accuracy: 0.768126904964447 F1-Score: 0.7240795989505374\n",
            "Epoch: 85 Last batch accuracy: 0.9689922332763672 Test accuracy: 0.768126904964447 F1-Score: 0.730978375974246\n",
            "Epoch: 86 Last batch accuracy: 0.9379844665527344 Test accuracy: 0.7598187327384949 F1-Score: 0.7251885676689669\n",
            "Epoch: 87 Last batch accuracy: 0.9147287011146545 Test accuracy: 0.7583081722259521 F1-Score: 0.729956945316409\n",
            "Epoch: 88 Last batch accuracy: 0.930232584476471 Test accuracy: 0.7613292932510376 F1-Score: 0.7223655571481657\n",
            "Epoch: 89 Last batch accuracy: 0.9379844665527344 Test accuracy: 0.7685045599937439 F1-Score: 0.7192636556443999\n",
            "Epoch: 90 Last batch accuracy: 0.9379844665527344 Test accuracy: 0.7715256810188293 F1-Score: 0.7289961622281169\n",
            "Epoch: 91 Last batch accuracy: 0.9689922332763672 Test accuracy: 0.7635951638221741 F1-Score: 0.7324081535664104\n",
            "Epoch: 92 Last batch accuracy: 0.9379844665527344 Test accuracy: 0.7666162848472595 F1-Score: 0.7214789156688022\n",
            "Epoch: 93 Last batch accuracy: 0.8914728760719299 Test accuracy: 0.7719033360481262 F1-Score: 0.7413579084977466\n",
            "Epoch: 94 Last batch accuracy: 0.9457364082336426 Test accuracy: 0.768882155418396 F1-Score: 0.7174237367576379\n",
            "Epoch: 95 Last batch accuracy: 0.9224806427955627 Test accuracy: 0.7628398537635803 F1-Score: 0.7209464044671557\n",
            "Epoch: 96 Last batch accuracy: 0.9147287011146545 Test accuracy: 0.7666162848472595 F1-Score: 0.7250104352139572\n",
            "Epoch: 97 Last batch accuracy: 0.961240291595459 Test accuracy: 0.7662386894226074 F1-Score: 0.7209269224122593\n",
            "Epoch: 98 Last batch accuracy: 0.9379844665527344 Test accuracy: 0.768126904964447 F1-Score: 0.7320191458220704\n",
            "Epoch: 99 Last batch accuracy: 0.9767441749572754 Test accuracy: 0.7696374654769897 F1-Score: 0.7248845226253899\n",
            "Epoch: 100 Last batch accuracy: 0.9457364082336426 Test accuracy: 0.7579305171966553 F1-Score: 0.719422111719844\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}